{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b7b2f251-6922-4008-8c69-337a1186f5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Yeni veri setini yükleme\n",
    "new_data_path = 'data/raw/1000Folk_Story_around_the_Globe.csv'\n",
    "df = pd.read_csv(new_data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3fedaf79-c789-41b2-ad09-3432048accd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['genre', 'source', 'region', 'title', 'full_text'], dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "509b90a0-e53d-4557-8e27-90bd090e9b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source                     region        \n",
       "African folktales          Nigeria            40\n",
       "                           South Africa       15\n",
       "Andersen fairy tales       Denmark            50\n",
       "Andrew Lang fairy tales    Scotland          116\n",
       "Arab folktales             Arab               24\n",
       "Asian folktales            China              80\n",
       "                           India              33\n",
       "                           Japan              67\n",
       "Australian folktales       Australia          31\n",
       "European folktales         British isles       6\n",
       "                           Celtic             26\n",
       "                           Czech              35\n",
       "                           Dutch              21\n",
       "                           England            43\n",
       "                           Germany            38\n",
       "                           Ireland            38\n",
       "                           Italy              30\n",
       "                           Norway             15\n",
       "                           Poland              7\n",
       "                           Portugal           34\n",
       "                           Romania            18\n",
       "                           Russia             30\n",
       "                           Sweden             28\n",
       "                           Ukraine            27\n",
       "                           Wales              23\n",
       "Filipino folktales         Philippines        61\n",
       "Grimm fairy tales          Germany           211\n",
       "Indian  folktales          India              26\n",
       "Indian folktales           India               3\n",
       "Native American folktales  Canada             26\n",
       "                           Native America     26\n",
       "North American folktales   USA                60\n",
       "South American folktales   Brazil             18\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['source', 'region']).size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6bd06fc8-b4e3-4d8e-a90d-50ba0cdfd7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"source\"] = df[\"source\"].str.strip().str.lower()\n",
    "df.loc[df[\"source\"] == 'indian  folktales', \"source\"] = 'indianfolktales'\n",
    "df[\"source\"] = df[\"source\"].str.replace(\" \", \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9c7901a-c414-4d5d-9a76-24004f51a684",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['source'] == 'asianfolktales') & (df['region'] == 'India'), 'source'] = 'indianfolktales'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b5ddf45-b2e8-4186-b945-d38cbcef9ccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source                   region        \n",
       "africanfolktales         Nigeria            40\n",
       "                         South Africa       15\n",
       "andersenfairytales       Denmark            50\n",
       "andrewlangfairytales     Scotland          116\n",
       "arabfolktales            Arab               24\n",
       "asianfolktales           China              80\n",
       "                         Japan              67\n",
       "australianfolktales      Australia          31\n",
       "europeanfolktales        British isles       6\n",
       "                         Celtic             26\n",
       "                         Czech              35\n",
       "                         Dutch              21\n",
       "                         England            43\n",
       "                         Germany            38\n",
       "                         Ireland            38\n",
       "                         Italy              30\n",
       "                         Norway             15\n",
       "                         Poland              7\n",
       "                         Portugal           34\n",
       "                         Romania            18\n",
       "                         Russia             30\n",
       "                         Sweden             28\n",
       "                         Ukraine            27\n",
       "                         Wales              23\n",
       "filipinofolktales        Philippines        61\n",
       "grimmfairytales          Germany           211\n",
       "indianfolktales          India              62\n",
       "nativeamericanfolktales  Canada             26\n",
       "                         Native America     26\n",
       "northamericanfolktales   USA                60\n",
       "southamericanfolktales   Brazil             18\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['source', 'region']).size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec5c67de-f895-486e-a401-1075ff4cdea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['genre', 'source', 'region', 'title', 'full_text'], dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "05f6e1a0-049a-4645-8fd7-978ecc80c3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'full_text': 'body', 'source': 'category'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161873ae-5d45-4ffa-b84c-fbf62f9c904f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e2ae47f9-ebf1-4404-b3f5-5e14bdbd4ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\bahar/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\bahar/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting text preprocessing...\n",
      "Text preprocessing completed.\n",
      "Selecting column: title_cleaned\n",
      "Fitting TitleTfidfTransformer...\n",
      "Transforming title text to TF-IDF features...\n",
      "Selecting column: body_cleaned\n",
      "Fitting BodyTfidfTransformer...\n",
      "Transforming body text to TF-IDF features...\n",
      "Starting text preprocessing...\n",
      "Text preprocessing completed.\n",
      "Selecting column: title_cleaned\n",
      "Transforming title text to TF-IDF features...\n",
      "Selecting column: body_cleaned\n",
      "Transforming body text to TF-IDF features...\n",
      "Accuracy: 0.85\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import emoji\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Make sure to download these resources if not already done\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Define custom transformer to select columns\n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column):\n",
    "        self.column = column\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        print(f\"Selecting column: {self.column}\")\n",
    "        return X[self.column]\n",
    "\n",
    "# Text preprocessor\n",
    "class TextPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        print(\"Starting text preprocessing...\")\n",
    "        X['title_cleaned'] = X['title'].apply(self.clean_text).apply(self.lemmatize_and_remove_stopwords)\n",
    "        X['body_cleaned'] = X['body'].apply(self.clean_text).apply(self.lemmatize_and_remove_stopwords)\n",
    "        print(\"Text preprocessing completed.\")\n",
    "        return X\n",
    "\n",
    "    def clean_text(self, text):\n",
    "        if pd.isnull(text):\n",
    "            return text\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'http://\\S+|https://\\S+|www\\.\\S+', '', text, flags=re.MULTILINE)\n",
    "        text = emoji.replace_emoji(text, replace='')\n",
    "        text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "        text = re.sub(r'\\d', ' ', text)\n",
    "        text = re.sub(r'\\n', ' ', text)\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        return text.strip()\n",
    "\n",
    "    def lemmatize_and_remove_stopwords(self, text):\n",
    "        if pd.isna(text):\n",
    "            return ''  # NaN değerler için boş string döndür\n",
    "        if text == \"\":\n",
    "            return text\n",
    "        words = text.split()\n",
    "        lemmatized_words = [self.lemmatizer.lemmatize(word) for word in words if word not in self.stop_words]\n",
    "        return ' '.join(lemmatized_words)\n",
    "\n",
    "# Custom transformer for body TF-IDF calculation with weight\n",
    "class BodyTfidfTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, weight=1.45):\n",
    "        self.weight = weight\n",
    "        self.tfidf_vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.6, min_df=2, ngram_range=(1, 1))\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        print(\"Fitting BodyTfidfTransformer...\")\n",
    "        self.tfidf_vectorizer.fit(X)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        print(\"Transforming body text to TF-IDF features...\")\n",
    "        tfidf_matrix = self.tfidf_vectorizer.transform(X)\n",
    "        return tfidf_matrix * self.weight\n",
    "\n",
    "# Custom transformer for title TF-IDF calculation\n",
    "class TitleTfidfTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.tfidf_vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.6, min_df=2, ngram_range=(1, 1))\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        print(\"Fitting TitleTfidfTransformer...\")\n",
    "        self.tfidf_vectorizer.fit(X)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        print(\"Transforming title text to TF-IDF features...\")\n",
    "        return self.tfidf_vectorizer.transform(X)\n",
    "\n",
    "# Create a pipeline for processing text data\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', TextPreprocessor()),\n",
    "    ('features', FeatureUnion([\n",
    "        ('title_tfidf', Pipeline([\n",
    "            ('selector', ColumnSelector('title_cleaned')),\n",
    "            ('tfidf', TitleTfidfTransformer())\n",
    "        ])),\n",
    "        ('body_tfidf', Pipeline([\n",
    "            ('selector', ColumnSelector('body_cleaned')),\n",
    "            ('tfidf', BodyTfidfTransformer())\n",
    "        ]))\n",
    "    ])),\n",
    "    ('classifier', RidgeClassifier(alpha=2, tol=0.01, random_state=42))\n",
    "])\n",
    "\n",
    "# Example data\n",
    "data = df\n",
    "\n",
    "# Split data\n",
    "X = data[['title', 'body']]\n",
    "y = data['category']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the pipeline on the test data\n",
    "accuracy = pipeline.score(X_test, y_test)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ab9ff99e-d167-4786-85fc-28c426ce1343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting text preprocessing...\n",
      "Text preprocessing completed.\n",
      "Selecting column: title_cleaned\n",
      "Transforming title text to TF-IDF features...\n",
      "Selecting column: body_cleaned\n",
      "Transforming body text to TF-IDF features...\n",
      "Precision: 0.90\n",
      "Recall: 0.87\n",
      "F1 Score: 0.86\n",
      "Classification Report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "       africanfolktales       1.00      0.94      0.97        16\n",
      "     andersenfairytales       1.00      0.75      0.86        12\n",
      "   andrewlangfairytales       0.91      0.40      0.56        25\n",
      "          arabfolktales       1.00      1.00      1.00         4\n",
      "         asianfolktales       0.97      0.94      0.95        31\n",
      "    australianfolktales       1.00      0.78      0.88         9\n",
      "      europeanfolktales       0.71      0.99      0.82        74\n",
      "      filipinofolktales       0.88      0.88      0.88         8\n",
      "        grimmfairytales       0.98      0.98      0.98        44\n",
      "        indianfolktales       1.00      0.57      0.73         7\n",
      "nativeamericanfolktales       1.00      1.00      1.00        10\n",
      " northamericanfolktales       1.00      0.72      0.84        18\n",
      " southamericanfolktales       1.00      1.00      1.00         4\n",
      "\n",
      "               accuracy                           0.87       262\n",
      "              macro avg       0.96      0.84      0.88       262\n",
      "           weighted avg       0.90      0.87      0.86       262\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Model tahminlerini yapma\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Performans metriklerini hesaplama\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "# Detaylı rapor\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8701ac87-4de3-4da7-b0e3-2dbfffa8d17f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\bahar/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\bahar/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data into training and test sets...\n",
      "Data splitting completed.\n",
      "Performing cross-validation...\n",
      "Starting text preprocessing...\n",
      "Text preprocessing completed.\n",
      "Selecting column: title_cleaned\n",
      "Fitting TitleTfidfTransformer...\n",
      "Transforming title text to TF-IDF features...\n",
      "Selecting column: body_cleaned\n",
      "Fitting BodyTfidfTransformer...\n",
      "Transforming body text to TF-IDF features...\n",
      "Starting text preprocessing...\n",
      "Text preprocessing completed.\n",
      "Selecting column: title_cleaned\n",
      "Transforming title text to TF-IDF features...\n",
      "Selecting column: body_cleaned\n",
      "Transforming body text to TF-IDF features...\n",
      "Starting text preprocessing...\n",
      "Text preprocessing completed.\n",
      "Selecting column: title_cleaned\n",
      "Fitting TitleTfidfTransformer...\n",
      "Transforming title text to TF-IDF features...\n",
      "Selecting column: body_cleaned\n",
      "Fitting BodyTfidfTransformer...\n",
      "Transforming body text to TF-IDF features...\n",
      "Starting text preprocessing...\n",
      "Text preprocessing completed.\n",
      "Selecting column: title_cleaned\n",
      "Transforming title text to TF-IDF features...\n",
      "Selecting column: body_cleaned\n",
      "Transforming body text to TF-IDF features...\n",
      "Starting text preprocessing...\n",
      "Text preprocessing completed.\n",
      "Selecting column: title_cleaned\n",
      "Fitting TitleTfidfTransformer...\n",
      "Transforming title text to TF-IDF features...\n",
      "Selecting column: body_cleaned\n",
      "Fitting BodyTfidfTransformer...\n",
      "Transforming body text to TF-IDF features...\n",
      "Starting text preprocessing...\n",
      "Text preprocessing completed.\n",
      "Selecting column: title_cleaned\n",
      "Transforming title text to TF-IDF features...\n",
      "Selecting column: body_cleaned\n",
      "Transforming body text to TF-IDF features...\n",
      "Starting text preprocessing...\n",
      "Text preprocessing completed.\n",
      "Selecting column: title_cleaned\n",
      "Fitting TitleTfidfTransformer...\n",
      "Transforming title text to TF-IDF features...\n",
      "Selecting column: body_cleaned\n",
      "Fitting BodyTfidfTransformer...\n",
      "Transforming body text to TF-IDF features...\n",
      "Starting text preprocessing...\n",
      "Text preprocessing completed.\n",
      "Selecting column: title_cleaned\n",
      "Transforming title text to TF-IDF features...\n",
      "Selecting column: body_cleaned\n",
      "Transforming body text to TF-IDF features...\n",
      "Starting text preprocessing...\n",
      "Text preprocessing completed.\n",
      "Selecting column: title_cleaned\n",
      "Fitting TitleTfidfTransformer...\n",
      "Transforming title text to TF-IDF features...\n",
      "Selecting column: body_cleaned\n",
      "Fitting BodyTfidfTransformer...\n",
      "Transforming body text to TF-IDF features...\n",
      "Starting text preprocessing...\n",
      "Text preprocessing completed.\n",
      "Selecting column: title_cleaned\n",
      "Transforming title text to TF-IDF features...\n",
      "Selecting column: body_cleaned\n",
      "Transforming body text to TF-IDF features...\n",
      "Starting text preprocessing...\n",
      "Text preprocessing completed.\n",
      "Selecting column: title_cleaned\n",
      "Fitting TitleTfidfTransformer...\n",
      "Transforming title text to TF-IDF features...\n",
      "Selecting column: body_cleaned\n",
      "Fitting BodyTfidfTransformer...\n",
      "Transforming body text to TF-IDF features...\n",
      "Starting text preprocessing...\n",
      "Text preprocessing completed.\n",
      "Selecting column: title_cleaned\n",
      "Transforming title text to TF-IDF features...\n",
      "Selecting column: body_cleaned\n",
      "Transforming body text to TF-IDF features...\n",
      "Starting text preprocessing...\n",
      "Text preprocessing completed.\n",
      "Selecting column: title_cleaned\n",
      "Fitting TitleTfidfTransformer...\n",
      "Transforming title text to TF-IDF features...\n",
      "Selecting column: body_cleaned\n",
      "Fitting BodyTfidfTransformer...\n",
      "Transforming body text to TF-IDF features...\n",
      "Starting text preprocessing...\n",
      "Text preprocessing completed.\n",
      "Selecting column: title_cleaned\n",
      "Transforming title text to TF-IDF features...\n",
      "Selecting column: body_cleaned\n",
      "Transforming body text to TF-IDF features...\n",
      "Starting text preprocessing...\n",
      "Text preprocessing completed.\n",
      "Selecting column: title_cleaned\n",
      "Fitting TitleTfidfTransformer...\n",
      "Transforming title text to TF-IDF features...\n",
      "Selecting column: body_cleaned\n",
      "Fitting BodyTfidfTransformer...\n",
      "Transforming body text to TF-IDF features...\n",
      "Starting text preprocessing...\n",
      "Text preprocessing completed.\n",
      "Selecting column: title_cleaned\n",
      "Transforming title text to TF-IDF features...\n",
      "Selecting column: body_cleaned\n",
      "Transforming body text to TF-IDF features...\n",
      "Starting text preprocessing...\n",
      "Text preprocessing completed.\n",
      "Selecting column: title_cleaned\n",
      "Fitting TitleTfidfTransformer...\n",
      "Transforming title text to TF-IDF features...\n",
      "Selecting column: body_cleaned\n",
      "Fitting BodyTfidfTransformer...\n",
      "Transforming body text to TF-IDF features...\n",
      "Starting text preprocessing...\n",
      "Text preprocessing completed.\n",
      "Selecting column: title_cleaned\n",
      "Transforming title text to TF-IDF features...\n",
      "Selecting column: body_cleaned\n",
      "Transforming body text to TF-IDF features...\n",
      "Starting text preprocessing...\n",
      "Text preprocessing completed.\n",
      "Selecting column: title_cleaned\n",
      "Fitting TitleTfidfTransformer...\n",
      "Transforming title text to TF-IDF features...\n",
      "Selecting column: body_cleaned\n",
      "Fitting BodyTfidfTransformer...\n",
      "Transforming body text to TF-IDF features...\n",
      "Starting text preprocessing...\n",
      "Text preprocessing completed.\n",
      "Selecting column: title_cleaned\n",
      "Transforming title text to TF-IDF features...\n",
      "Selecting column: body_cleaned\n",
      "Transforming body text to TF-IDF features...\n",
      "Starting text preprocessing...\n",
      "Text preprocessing completed.\n",
      "Selecting column: title_cleaned\n",
      "Fitting TitleTfidfTransformer...\n",
      "Transforming title text to TF-IDF features...\n",
      "Selecting column: body_cleaned\n",
      "Fitting BodyTfidfTransformer...\n",
      "Transforming body text to TF-IDF features...\n",
      "Starting text preprocessing...\n",
      "Text preprocessing completed.\n",
      "Selecting column: title_cleaned\n",
      "Transforming title text to TF-IDF features...\n",
      "Selecting column: body_cleaned\n",
      "Transforming body text to TF-IDF features...\n",
      "Starting text preprocessing...\n",
      "Text preprocessing completed.\n",
      "Selecting column: title_cleaned\n",
      "Fitting TitleTfidfTransformer...\n",
      "Transforming title text to TF-IDF features...\n",
      "Selecting column: body_cleaned\n",
      "Fitting BodyTfidfTransformer...\n",
      "Transforming body text to TF-IDF features...\n",
      "Starting text preprocessing...\n",
      "Text preprocessing completed.\n",
      "Selecting column: title_cleaned\n",
      "Transforming title text to TF-IDF features...\n",
      "Selecting column: body_cleaned\n",
      "Transforming body text to TF-IDF features...\n",
      "Starting text preprocessing...\n",
      "Text preprocessing completed.\n",
      "Selecting column: title_cleaned\n",
      "Fitting TitleTfidfTransformer...\n",
      "Transforming title text to TF-IDF features...\n",
      "Selecting column: body_cleaned\n",
      "Fitting BodyTfidfTransformer...\n",
      "Transforming body text to TF-IDF features...\n",
      "Starting text preprocessing...\n",
      "Text preprocessing completed.\n",
      "Selecting column: title_cleaned\n",
      "Transforming title text to TF-IDF features...\n",
      "Selecting column: body_cleaned\n",
      "Transforming body text to TF-IDF features...\n",
      "Starting text preprocessing...\n",
      "Text preprocessing completed.\n",
      "Selecting column: title_cleaned\n",
      "Fitting TitleTfidfTransformer...\n",
      "Transforming title text to TF-IDF features...\n",
      "Selecting column: body_cleaned\n",
      "Fitting BodyTfidfTransformer...\n",
      "Transforming body text to TF-IDF features...\n",
      "Starting text preprocessing...\n",
      "Text preprocessing completed.\n",
      "Selecting column: title_cleaned\n",
      "Transforming title text to TF-IDF features...\n",
      "Selecting column: body_cleaned\n",
      "Transforming body text to TF-IDF features...\n",
      "Starting text preprocessing...\n",
      "Text preprocessing completed.\n",
      "Selecting column: title_cleaned\n",
      "Fitting TitleTfidfTransformer...\n",
      "Transforming title text to TF-IDF features...\n",
      "Selecting column: body_cleaned\n",
      "Fitting BodyTfidfTransformer...\n",
      "Transforming body text to TF-IDF features...\n",
      "Starting text preprocessing...\n",
      "Text preprocessing completed.\n",
      "Selecting column: title_cleaned\n",
      "Transforming title text to TF-IDF features...\n",
      "Selecting column: body_cleaned\n",
      "Transforming body text to TF-IDF features...\n",
      "Cross-validation scores: [0.91428571 0.82857143 0.88571429 0.92857143 0.84285714 0.84285714\n",
      " 0.91428571 0.87142857 0.81428571 0.85507246 0.82608696 0.85507246\n",
      " 0.85507246 0.85507246 0.82608696]\n",
      "Mean cross-validation accuracy: 0.8610213940648721\n",
      "Training the pipeline...\n",
      "Starting text preprocessing...\n",
      "Text preprocessing completed.\n",
      "Selecting column: title_cleaned\n",
      "Fitting TitleTfidfTransformer...\n",
      "Transforming title text to TF-IDF features...\n",
      "Selecting column: body_cleaned\n",
      "Fitting BodyTfidfTransformer...\n",
      "Transforming body text to TF-IDF features...\n",
      "Pipeline training completed.\n",
      "Making predictions and evaluating the model...\n",
      "Starting text preprocessing...\n",
      "Text preprocessing completed.\n",
      "Selecting column: title_cleaned\n",
      "Transforming title text to TF-IDF features...\n",
      "Selecting column: body_cleaned\n",
      "Transforming body text to TF-IDF features...\n",
      "Prediction and evaluation completed.\n",
      "Model accuracy: 0.8702290076335878\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from scipy.sparse import hstack\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import emoji\n",
    "import nltk\n",
    "\n",
    "# Make sure to download these resources if not already done\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Define custom transformer to select columns\n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column):\n",
    "        self.column = column\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        print(f\"Selecting column: {self.column}\")\n",
    "        return X[self.column]\n",
    "\n",
    "# Text preprocessor\n",
    "class TextPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        print(\"Starting text preprocessing...\")\n",
    "        X['title_cleaned'] = X['title'].apply(self.clean_text).apply(self.lemmatize_and_remove_stopwords)\n",
    "        X['body_cleaned'] = X['body'].apply(self.clean_text).apply(self.lemmatize_and_remove_stopwords)\n",
    "        print(\"Text preprocessing completed.\")\n",
    "        return X\n",
    "\n",
    "    def clean_text(self, text):\n",
    "        if pd.isnull(text):\n",
    "            return text\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'http://\\S+|https://\\S+|www\\.\\S+', '', text, flags=re.MULTILINE)\n",
    "        text = emoji.replace_emoji(text, replace='')\n",
    "        text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "        text = re.sub(r'\\d', ' ', text)\n",
    "        text = re.sub(r'\\n', ' ', text)\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        return text.strip()\n",
    "\n",
    "    def lemmatize_and_remove_stopwords(self, text):\n",
    "        if pd.isna(text):\n",
    "            return ''  # NaN değerler için boş string döndür\n",
    "        if text == \"\":\n",
    "            return text\n",
    "        words = text.split()\n",
    "        lemmatized_words = [self.lemmatizer.lemmatize(word) for word in words if word not in self.stop_words]\n",
    "        return ' '.join(lemmatized_words)\n",
    "\n",
    "# Custom transformer for body TF-IDF calculation with weight\n",
    "class BodyTfidfTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, weight=1.45):\n",
    "        self.weight = weight\n",
    "        self.tfidf_vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.6, min_df=2, ngram_range=(1, 1))\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        print(\"Fitting BodyTfidfTransformer...\")\n",
    "        self.tfidf_vectorizer.fit(X)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        print(\"Transforming body text to TF-IDF features...\")\n",
    "        tfidf_matrix = self.tfidf_vectorizer.transform(X)\n",
    "        return tfidf_matrix * self.weight\n",
    "\n",
    "# Custom transformer for title TF-IDF calculation\n",
    "class TitleTfidfTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.tfidf_vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.6, min_df=2, ngram_range=(1, 1))\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        print(\"Fitting TitleTfidfTransformer...\")\n",
    "        self.tfidf_vectorizer.fit(X)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        print(\"Transforming title text to TF-IDF features...\")\n",
    "        return self.tfidf_vectorizer.transform(X)\n",
    "\n",
    "# Create a pipeline for processing text data\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', TextPreprocessor()),\n",
    "    ('features', FeatureUnion([\n",
    "        ('title_tfidf', Pipeline([\n",
    "            ('selector', ColumnSelector('title_cleaned')),\n",
    "            ('tfidf', TitleTfidfTransformer())\n",
    "        ])),\n",
    "        ('body_tfidf', Pipeline([\n",
    "            ('selector', ColumnSelector('body_cleaned')),\n",
    "            ('tfidf', BodyTfidfTransformer())\n",
    "        ]))\n",
    "    ])),\n",
    "    ('classifier', RidgeClassifier(alpha=2, tol=0.01, random_state=42))\n",
    "])\n",
    "# Split data\n",
    "print(\"Splitting data into training and test sets...\")\n",
    "X = df[['title', 'body']]\n",
    "y = df['category']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "print(\"Data splitting completed.\")\n",
    "\n",
    "# Perform cross-validation on preprocessed data\n",
    "print(\"Performing cross-validation...\")\n",
    "cv_scores = cross_val_score(pipeline, X_train, y_train, cv=15)  # 5-fold cross-validation\n",
    "print(f\"Cross-validation scores: {cv_scores}\")\n",
    "print(f\"Mean cross-validation accuracy: {np.mean(cv_scores)}\")\n",
    "\n",
    "# Train the pipeline\n",
    "print(\"Training the pipeline...\")\n",
    "pipeline.fit(X_train, y_train)\n",
    "print(\"Pipeline training completed.\")\n",
    "\n",
    "# Predict and evaluate the model\n",
    "print(\"Making predictions and evaluating the model...\")\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(\"Prediction and evaluation completed.\")\n",
    "\n",
    "# Output results\n",
    "accuracy = (y_pred == y_test).mean()\n",
    "print(f\"Model accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ad5624-1a3f-42c0-be64-1226b03f5c98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
